{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1+0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = tf.Variable(tf.random_uniform([1],-1.0, 1.0))\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y = Weights*x_data + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.0046052] [0.49472705]\n",
      "20 [0.0497934] [0.32702765]\n",
      "40 [0.08447614] [0.30835694]\n",
      "60 [0.09520003] [0.30258396]\n",
      "80 [0.09851587] [0.30079895]\n",
      "100 [0.09954113] [0.30024704]\n",
      "120 [0.09985812] [0.3000764]\n",
      "140 [0.09995614] [0.30002362]\n",
      "160 [0.09998642] [0.3000073]\n",
      "180 [0.09999578] [0.30000228]\n",
      "200 [0.09999869] [0.30000073]\n",
      "220 [0.09999958] [0.30000025]\n",
      "240 [0.09999987] [0.30000007]\n",
      "260 [0.0999999] [0.30000007]\n",
      "280 [0.0999999] [0.30000007]\n",
      "300 [0.0999999] [0.30000007]\n",
      "320 [0.0999999] [0.30000007]\n",
      "340 [0.0999999] [0.30000007]\n",
      "360 [0.0999999] [0.30000007]\n",
      "380 [0.0999999] [0.30000007]\n",
      "400 [0.0999999] [0.30000007]\n",
      "420 [0.0999999] [0.30000007]\n",
      "440 [0.0999999] [0.30000007]\n",
      "460 [0.0999999] [0.30000007]\n",
      "480 [0.0999999] [0.30000007]\n",
      "500 [0.0999999] [0.30000007]\n",
      "520 [0.0999999] [0.30000007]\n",
      "540 [0.0999999] [0.30000007]\n",
      "560 [0.0999999] [0.30000007]\n",
      "580 [0.0999999] [0.30000007]\n",
      "600 [0.0999999] [0.30000007]\n",
      "620 [0.0999999] [0.30000007]\n",
      "640 [0.0999999] [0.30000007]\n",
      "660 [0.0999999] [0.30000007]\n",
      "680 [0.0999999] [0.30000007]\n",
      "700 [0.0999999] [0.30000007]\n",
      "720 [0.0999999] [0.30000007]\n",
      "740 [0.0999999] [0.30000007]\n",
      "760 [0.0999999] [0.30000007]\n",
      "780 [0.0999999] [0.30000007]\n",
      "800 [0.0999999] [0.30000007]\n",
      "820 [0.0999999] [0.30000007]\n",
      "840 [0.0999999] [0.30000007]\n",
      "860 [0.0999999] [0.30000007]\n",
      "880 [0.0999999] [0.30000007]\n",
      "900 [0.0999999] [0.30000007]\n",
      "920 [0.0999999] [0.30000007]\n",
      "940 [0.0999999] [0.30000007]\n",
      "960 [0.0999999] [0.30000007]\n",
      "980 [0.0999999] [0.30000007]\n",
      "1000 [0.0999999] [0.30000007]\n",
      "1020 [0.0999999] [0.30000007]\n",
      "1040 [0.0999999] [0.30000007]\n",
      "1060 [0.0999999] [0.30000007]\n",
      "1080 [0.0999999] [0.30000007]\n",
      "1100 [0.0999999] [0.30000007]\n",
      "1120 [0.0999999] [0.30000007]\n",
      "1140 [0.0999999] [0.30000007]\n",
      "1160 [0.0999999] [0.30000007]\n",
      "1180 [0.0999999] [0.30000007]\n",
      "1200 [0.0999999] [0.30000007]\n",
      "1220 [0.0999999] [0.30000007]\n",
      "1240 [0.0999999] [0.30000007]\n",
      "1260 [0.0999999] [0.30000007]\n",
      "1280 [0.0999999] [0.30000007]\n",
      "1300 [0.0999999] [0.30000007]\n",
      "1320 [0.0999999] [0.30000007]\n",
      "1340 [0.0999999] [0.30000007]\n",
      "1360 [0.0999999] [0.30000007]\n",
      "1380 [0.0999999] [0.30000007]\n",
      "1400 [0.0999999] [0.30000007]\n",
      "1420 [0.0999999] [0.30000007]\n",
      "1440 [0.0999999] [0.30000007]\n",
      "1460 [0.0999999] [0.30000007]\n",
      "1480 [0.0999999] [0.30000007]\n",
      "1500 [0.0999999] [0.30000007]\n",
      "1520 [0.0999999] [0.30000007]\n",
      "1540 [0.0999999] [0.30000007]\n",
      "1560 [0.0999999] [0.30000007]\n",
      "1580 [0.0999999] [0.30000007]\n",
      "1600 [0.0999999] [0.30000007]\n",
      "1620 [0.0999999] [0.30000007]\n",
      "1640 [0.0999999] [0.30000007]\n",
      "1660 [0.0999999] [0.30000007]\n",
      "1680 [0.0999999] [0.30000007]\n",
      "1700 [0.0999999] [0.30000007]\n",
      "1720 [0.0999999] [0.30000007]\n",
      "1740 [0.0999999] [0.30000007]\n",
      "1760 [0.0999999] [0.30000007]\n",
      "1780 [0.0999999] [0.30000007]\n",
      "1800 [0.0999999] [0.30000007]\n",
      "1820 [0.0999999] [0.30000007]\n",
      "1840 [0.0999999] [0.30000007]\n",
      "1860 [0.0999999] [0.30000007]\n",
      "1880 [0.0999999] [0.30000007]\n",
      "1900 [0.0999999] [0.30000007]\n",
      "1920 [0.0999999] [0.30000007]\n",
      "1940 [0.0999999] [0.30000007]\n",
      "1960 [0.0999999] [0.30000007]\n",
      "1980 [0.0999999] [0.30000007]\n",
      "2000 [0.0999999] [0.30000007]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "steps = 2001\n",
    "for step in range(steps):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(Weights), sess.run(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# How to run a operation\n",
    "matrix1 = tf.constant([[3,3]])\n",
    "matrix2 = tf.constant([[2],[2]])\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# method 1 \n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# How to define a Variable in tf\n",
    "state = tf.Variable(0, name='counter')\n",
    "\n",
    "# Define a constant variable\n",
    "one = tf.constant(1)\n",
    "\n",
    "# Define a add operation\n",
    "new_value = tf.add(state, one)\n",
    "\n",
    "# Update state to a new_value\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# If you define a variable, you must initialize it\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "steps = 30\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(steps):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "# How to use placeholder to save variable and read data from outside\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict = {input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use activation function\n",
    "# we can use nonlnear function to do many thing. so, activation function is used to create nonlinear function\n",
    "# exp, for linear function f = Wx, we get g = sigmoid(Wx) as a new nonlinear function\n",
    "# when you use CNN , we recommend you to use relu as activation function, and we recommend you to use tanh when doing RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding layer to network\n",
    "def add_layer(inputs, in_size, out_size, activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function == None:\n",
    "        return Wx_plus_b\n",
    "    else:\n",
    "        return activation_function(Wx_plus_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32506165\n",
      "0.032783564\n",
      "0.016080404\n",
      "0.011270444\n",
      "0.008981929\n",
      "0.0075364304\n",
      "0.006516556\n",
      "0.005716302\n",
      "0.0050799428\n",
      "0.004593546\n",
      "0.0042557023\n",
      "0.0040142597\n",
      "0.0038436523\n",
      "0.003719515\n",
      "0.003628124\n",
      "0.0035486238\n",
      "0.0034823453\n",
      "0.0034245173\n",
      "0.0033738574\n",
      "0.003329802\n"
     ]
    }
   ],
   "source": [
    "# Building a network\n",
    "x_data = np.linspace(-1, 1, 300, dtype=np.float32)[:, np.newaxis] # 300 items with a same gap from -1 to 1, add a dimension [1,2,3] => [[1],[2],[3]]\n",
    "noise = np.random.normal(0, 0.05 ,x_data.shape).astype(np.float32)\n",
    "y_data = np.square(x_data)-0.5 + noise\n",
    "\n",
    "# Use placeholder to define out inputs\n",
    "xs = tf.placeholder(tf.float32, [None,1])\n",
    "ys = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "# Add layer for network\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu) # 1 x 10 layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None) # 10 x 1 layer\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training step\n",
    "steps = 1000\n",
    "for i in range(steps):\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        print(sess.run(loss, feed_dict = {xs: x_data, ys: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "# plot by matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs:x_data, ys:y_data})\n",
    "    if i % 50 == 0:\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs:x_data})\n",
    "        lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "        plt.pause(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed up your network\n",
    "# 1. stochastic gradient descent SGD\n",
    "# 2. use momentum, AdaGrad\n",
    "# 3. RMSProp\n",
    "# 4. Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensorboard to show your network details\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1], name='x_in')\n",
    "ys = tf.placeholder(tf.float32, [None, 1], name='y_in')\n",
    "\n",
    "def add_layer(inputs, int_size, out_size, activation_function=None):\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([int_size, out_size]), name='W')\n",
    "        with tf.name_scope('Biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]), name='b')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(biases, tf.matmul(inputs, Weights))\n",
    "        if activation_function == None:\n",
    "            return Wx_plus_b\n",
    "        else:\n",
    "            return activation_function(Wx_plus_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session() # get session\n",
    "# tf.train.SummaryWriter soon be deprecated, use following\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "# use 'tensorboard -logdir logs' in terminal and then you can see your network framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.1362\n",
      "0.6361\n",
      "0.7352\n",
      "0.7795\n",
      "0.8027\n",
      "0.8202\n",
      "0.834\n",
      "0.8368\n",
      "0.8481\n",
      "0.8541\n",
      "0.8537\n",
      "0.8558\n",
      "0.8609\n",
      "0.8631\n",
      "0.8654\n",
      "0.8653\n",
      "0.8714\n",
      "0.8678\n",
      "0.8759\n",
      "0.8773\n",
      "0.8776\n",
      "0.8736\n",
      "0.8776\n",
      "0.8813\n",
      "0.8792\n",
      "0.8813\n",
      "0.8843\n",
      "0.8842\n",
      "0.8816\n",
      "0.8861\n",
      "0.8839\n",
      "0.8864\n",
      "0.8877\n",
      "0.8881\n",
      "0.8864\n",
      "0.8874\n",
      "0.8896\n",
      "0.8871\n",
      "0.8896\n",
      "0.8914\n",
      "0.8904\n",
      "0.8933\n",
      "0.893\n",
      "0.893\n",
      "0.8923\n",
      "0.8929\n",
      "0.8943\n",
      "0.8954\n",
      "0.8952\n",
      "0.8951\n",
      "0.899\n",
      "0.8946\n",
      "0.8952\n",
      "0.894\n",
      "0.8958\n",
      "0.8924\n",
      "0.8967\n",
      "0.8991\n",
      "0.8953\n",
      "0.8998\n",
      "0.8984\n",
      "0.8983\n",
      "0.8957\n",
      "0.8978\n",
      "0.8999\n",
      "0.9005\n",
      "0.8918\n",
      "0.9017\n",
      "0.8994\n",
      "0.8996\n",
      "0.9025\n",
      "0.901\n",
      "0.9019\n",
      "0.9025\n",
      "0.9024\n",
      "0.9018\n",
      "0.8991\n",
      "0.9045\n",
      "0.8997\n",
      "0.8987\n",
      "0.8985\n",
      "0.9034\n",
      "0.9055\n",
      "0.8996\n",
      "0.9041\n",
      "0.9048\n",
      "0.9048\n",
      "0.9033\n",
      "0.903\n",
      "0.906\n",
      "0.9069\n",
      "0.9055\n",
      "0.9056\n",
      "0.9066\n",
      "0.9024\n",
      "0.9039\n",
      "0.904\n",
      "0.9064\n",
      "0.9047\n",
      "0.8991\n",
      "0.9085\n",
      "0.9059\n",
      "0.9043\n",
      "0.908\n",
      "0.9058\n",
      "0.9076\n",
      "0.9069\n",
      "0.9059\n",
      "0.9033\n",
      "0.9061\n",
      "0.9069\n",
      "0.9102\n",
      "0.9082\n",
      "0.9064\n",
      "0.9082\n",
      "0.9057\n",
      "0.9044\n",
      "0.909\n",
      "0.9067\n",
      "0.9057\n",
      "0.9091\n",
      "0.9068\n",
      "0.9064\n",
      "0.9088\n",
      "0.9095\n",
      "0.9084\n",
      "0.9101\n",
      "0.9079\n",
      "0.9045\n",
      "0.9098\n",
      "0.9106\n",
      "0.9091\n",
      "0.9074\n",
      "0.9111\n",
      "0.9079\n",
      "0.9076\n",
      "0.906\n",
      "0.9066\n",
      "0.91\n",
      "0.9074\n",
      "0.9099\n",
      "0.9106\n",
      "0.9122\n",
      "0.9128\n",
      "0.9137\n",
      "0.9124\n",
      "0.9094\n",
      "0.9118\n",
      "0.9105\n",
      "0.9068\n",
      "0.9073\n",
      "0.9058\n",
      "0.9101\n",
      "0.9115\n",
      "0.9095\n",
      "0.9109\n",
      "0.9089\n",
      "0.9113\n",
      "0.9112\n",
      "0.9083\n",
      "0.9094\n",
      "0.9118\n",
      "0.9111\n",
      "0.9097\n",
      "0.9137\n",
      "0.9111\n",
      "0.9122\n",
      "0.9139\n",
      "0.915\n",
      "0.9139\n",
      "0.9111\n",
      "0.9116\n",
      "0.9129\n",
      "0.91\n",
      "0.9148\n",
      "0.9097\n",
      "0.911\n",
      "0.9126\n",
      "0.913\n",
      "0.9137\n",
      "0.9136\n",
      "0.9102\n",
      "0.9125\n",
      "0.9037\n",
      "0.911\n",
      "0.9121\n",
      "0.9142\n",
      "0.9129\n",
      "0.9149\n",
      "0.9161\n",
      "0.9142\n",
      "0.9147\n",
      "0.9124\n",
      "0.9148\n",
      "0.9153\n",
      "0.9141\n",
      "0.9113\n",
      "0.9137\n",
      "0.9129\n",
      "0.9123\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to solve overfitting\n",
    "# 1. enlarge the training data\n",
    "# 2. use l2 regularization\n",
    "# 3. use dropout ( ignore some cells in the network)\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# load data\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, layer_name, activation_function=None, ):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    # here to dropout\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b, )\n",
    "    tf.summary.histogram(layer_name + '/outputs', outputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 64])  # 8x8\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "l1 = add_layer(xs, 64, 50, 'l1', activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l1, 50, 10, 'l2', activation_function=tf.nn.softmax)\n",
    "\n",
    "# the loss between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))  # loss\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "# summary writer goes in here\n",
    "train_writer = tf.summary.FileWriter(\"logs/train\", sess.graph)\n",
    "test_writer = tf.summary.FileWriter(\"logs/test\", sess.graph)\n",
    "\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for i in range(500):\n",
    "    # here to determine the keeping probability\n",
    "    sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        # record loss\n",
    "        train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})\n",
    "        test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})\n",
    "        train_writer.add_summary(train_result, i)\n",
    "        test_writer.add_summary(test_result, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
